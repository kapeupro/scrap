# LinkedScraper - Alternative Simple Ã  Phantombuster

ğŸš€ **Extraction de profils LinkedIn + Enrichissement d'emails en un clic**

## ğŸ¯ FonctionnalitÃ©s

- âœ… Extraction de profils LinkedIn depuis une URL de recherche
- âœ… Enrichissement automatique des emails via Hunter.io
- âœ… Export CSV en un clic
- âœ… Interface simple et moderne
- âœ… Plans tarifaires transparents (pas de crÃ©dits complexes)
- âœ… Limites mensuelles claires

## ğŸ“¦ Stack Technique

- **Frontend**: Next.js 14 + Tailwind CSS
- **Backend**: Next.js API Routes
- **Base de donnÃ©es**: Supabase
- **Scraping**: Puppeteer
- **Enrichissement**: Hunter.io API
- **Paiements**: Stripe
- **DÃ©ploiement**: Vercel

## ğŸš€ Installation Rapide

### 1. Cloner le projet

```bash
git clone [votre-repo]
cd linkedscraper
npm install
```

### 2. Configuration Supabase

1. CrÃ©ez un compte sur [Supabase](https://supabase.com)
2. CrÃ©ez un nouveau projet
3. Allez dans SQL Editor et exÃ©cutez le script `database-schema.sql`
4. RÃ©cupÃ©rez vos clÃ©s API dans Settings > API

### 3. Configuration des variables d'environnement

CrÃ©ez un fichier `.env.local` Ã  la racine :

```env
# Supabase
NEXT_PUBLIC_SUPABASE_URL=votre_url_supabase
NEXT_PUBLIC_SUPABASE_ANON_KEY=votre_cle_anon
SUPABASE_SERVICE_ROLE_KEY=votre_cle_service

# Hunter.io (pour l'enrichissement d'emails)
HUNTER_API_KEY=votre_cle_hunter

# Stripe (pour les paiements)
STRIPE_SECRET_KEY=votre_cle_secrete_stripe
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=votre_cle_publique_stripe
STRIPE_WEBHOOK_SECRET=votre_webhook_secret

# App
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=generer_une_cle_secrete_aleatoire
```

### 4. Lancer le projet

```bash
npm run dev
```

Ouvrez [http://localhost:3000](http://localhost:3000)

## ğŸ’° Plans Tarifaires

| Plan | Prix | Extractions/mois | Emails/mois |
|------|------|------------------|-------------|
| **Starter** | 19â‚¬/mois | 1,000 profils | 100 emails |
| **Pro** | 49â‚¬/mois | 5,000 profils | 500 emails |
| **Agency** | 99â‚¬/mois | 20,000 profils | 2,000 emails |

## ğŸ› ï¸ Structure du Projet

```
src/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ scrape.js       # API de scraping LinkedIn
â”‚   â”‚   â”œâ”€â”€ enrich.js       # API d'enrichissement emails
â”‚   â”‚   â”œâ”€â”€ export.js       # API d'export CSV
â”‚   â”‚   â”œâ”€â”€ usage.js        # API de suivi d'usage
â”‚   â”‚   â””â”€â”€ webhook.js      # Webhook Stripe
â”‚   â”œâ”€â”€ index.js            # Dashboard principal
â”‚   â”œâ”€â”€ landing.js          # Page d'accueil
â”‚   â”œâ”€â”€ login.js            # Page de connexion
â”‚   â””â”€â”€ pricing.js          # Page de tarification
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ScrapingForm.js     # Formulaire d'extraction
â”‚   â”œâ”€â”€ ResultsTable.js     # Tableau des rÃ©sultats
â”‚   â”œâ”€â”€ ExportButton.js     # Bouton d'export
â”‚   â””â”€â”€ UsageStats.js       # Statistiques d'usage
â””â”€â”€ lib/
    â”œâ”€â”€ scraper.js          # Logique de scraping
    â”œâ”€â”€ enricher.js         # Logique d'enrichissement
    â””â”€â”€ supabase.js         # Configuration Supabase
```

## ğŸ“ Utilisation

1. **Connexion**: CrÃ©ez un compte ou connectez-vous
2. **Coller l'URL**: Collez une URL de recherche LinkedIn
3. **Extraction**: Cliquez sur "Extraire les Profils"
4. **Enrichissement** (optionnel): Cliquez sur "Enrichir les emails"
5. **Export**: TÃ©lÃ©chargez les rÃ©sultats en CSV

## ğŸš€ DÃ©ploiement sur Vercel

1. Connectez votre repo GitHub Ã  Vercel
2. Ajoutez les variables d'environnement
3. DÃ©ployez en un clic

```bash
vercel --prod
```

## ğŸ”’ SÃ©curitÃ©

- âœ… Authentification via Supabase Auth
- âœ… Row Level Security (RLS) activÃ©
- âœ… API sÃ©curisÃ©es avec tokens JWT
- âœ… Limites de taux pour Ã©viter les abus
- âœ… Headers rÃ©alistes pour Ã©viter la dÃ©tection

## ğŸ“ˆ Roadmap

### Phase 1 (Semaines 1-2) âœ…
- [x] MVP fonctionnel
- [x] Scraping LinkedIn basique
- [x] Enrichissement emails
- [x] Export CSV
- [x] 3 plans tarifaires

### Phase 2 (Semaines 3-4)
- [ ] Extension Chrome
- [ ] Templates de recherche
- [ ] Export formats multiples (Excel, JSON)
- [ ] Webhook pour intÃ©grations

### Phase 3 (Mois 2)
- [ ] IntÃ©gration CRM (HubSpot, Pipedrive)
- [ ] Analytics dashboard
- [ ] API publique
- [ ] Bulk operations

### Phase 4 (Mois 3)
- [ ] IA pour scoring de leads
- [ ] Outreach automatisÃ©
- [ ] SÃ©quences d'emails
- [ ] A/B testing

## ğŸ¤ Support

- Email: support@linkedscraper.com
- Documentation: [docs.linkedscraper.com](https://docs.linkedscraper.com)
- Discord: [Rejoindre la communautÃ©](https://discord.gg/linkedscraper)

## ğŸ“„ Licence

MIT License - Utilisez librement pour vos projets

---

**LinkedScraper** - L'alternative simple et efficace Ã  Phantombuster ğŸš€
# Google Maps Places Scraper

Une application web moderne pour extraire des donnÃ©es d'Ã©tablissements (restaurants, hÃ´tels, supermarchÃ©s, etc.) avec export CSV/JSON.

## ğŸš€ FonctionnalitÃ©s

- **Recherche d'Ã©tablissements** : Restaurants, supermarchÃ©s, hÃ´tels, pharmacies, etc.
- **Recherche par ville** : Paris, Lyon, Marseille, Nice, et plus
- **Export des donnÃ©es** : CSV et JSON
- **Interface moderne** : Design responsive avec Tailwind CSS
- **Authentification** : SystÃ¨me de connexion avec Supabase
- **Limites d'utilisation** : Gestion des quotas mensuels

## ğŸ“‹ PrÃ©requis

- Node.js 18+
- Compte Supabase (gratuit)
- NPM ou Yarn

## ğŸ› ï¸ Installation

1. **Cloner le repository**
```bash
git clone https://github.com/kapeupro/scrap.git
cd scrap
```

2. **Installer les dÃ©pendances**
```bash
npm install
```

3. **Configuration des variables d'environnement**

Copier le fichier `.env.example` en `.env.local` :
```bash
cp .env.example .env.local
```

Puis remplir les variables avec vos clÃ©s Supabase :
- `NEXT_PUBLIC_SUPABASE_URL` : URL de votre projet Supabase
- `NEXT_PUBLIC_SUPABASE_ANON_KEY` : ClÃ© publique anonyme
- `SUPABASE_SERVICE_ROLE_KEY` : ClÃ© de service (privÃ©e)

4. **Configurer la base de donnÃ©es Supabase**

ExÃ©cuter le script SQL `database-schema-simple.sql` dans l'Ã©diteur SQL de Supabase.

5. **Lancer l'application**
```bash
npm run dev
```

L'application sera accessible sur http://localhost:3000

## ğŸ¯ Utilisation

1. **CrÃ©er un compte** : Inscription via email/mot de passe
2. **Se connecter** : Connexion avec vos identifiants
3. **Rechercher** : Entrer un type d'Ã©tablissement et une ville
4. **Exporter** : TÃ©lÃ©charger les rÃ©sultats en CSV ou JSON

## ğŸ—ï¸ Technologies utilisÃ©es

- **Frontend** : Next.js 14, React, Tailwind CSS
- **Backend** : API Routes Next.js
- **Base de donnÃ©es** : Supabase (PostgreSQL)
- **API de donnÃ©es** : OpenStreetMap Overpass API
- **Authentification** : Supabase Auth

## ğŸ“ Structure du projet

```
scrap/
â”œâ”€â”€ components/          # Composants React
â”œâ”€â”€ lib/                # Utilitaires et API
â”œâ”€â”€ pages/              # Pages Next.js
â”‚   â”œâ”€â”€ api/           # API Routes
â”‚   â””â”€â”€ index.js       # Page principale
â”œâ”€â”€ styles/            # Styles CSS
â””â”€â”€ database-schema-simple.sql  # SchÃ©ma de base de donnÃ©es
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“„ Licence

MIT

## ğŸ‘¨â€ğŸ’» Auteur

DÃ©veloppÃ© avec â¤ï¸ par [kapeupro](https://github.com/kapeupro)
